{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**Hi :)**\n",
        "\n",
        "**To run our program please follow the next steps:**\n",
        "\n",
        "**1. Connect to your drive and upload and unzip the requires files(e.g. datasets)**\n",
        "\n",
        "**2. Fill the globals section**\n",
        "\n",
        "**3. Choose code fo running (according to dataset - Monet/Photos)**\n",
        "\n",
        "**4. Choose main type(train or test)**"
      ],
      "metadata": {
        "id": "jPw8-vdMcvWi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Please connect to your drive for upload the files**"
      ],
      "metadata": {
        "id": "DBkG6S90Vcl1"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BCcKerpHtjva"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive \n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unzip Dataset [Example below]**"
      ],
      "metadata": {
        "id": "6mEOHCOpWjK8"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "urEy1Ubut09L"
      },
      "outputs": [],
      "source": [
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Datasets/arbi.zip'\n",
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Datasets/Photos/train_photos.zip'\n",
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Datasets/Photos/valid_photos.zip'\n",
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Datasets/Monet/train_preview.zip'\n",
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Datasets/Monet/valid_preview.zip'\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Unzip Trained models + Test files [Example below]**"
      ],
      "metadata": {
        "id": "bhB9EERTqpvq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Trained_Models/Separate_Models/Trained_Models.zip'\n",
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Trained_Models/Combined_Models/Trained_Combined_Models.zip'\n",
        "!unzip '/content/gdrive/MyDrive/DeepLearning/Test/test.zip'\n"
      ],
      "metadata": {
        "id": "olEx9lU3qBlY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For running trained model - please fill the following globals**\n"
      ],
      "metadata": {
        "id": "KJEwJrdKbjJF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For running trained model - please fill the following globals\n",
        "DATA_PATH = \"\"  # FOR EXAMPLE: \"./test/monet_blocks\"\n",
        "TRAINED_MODEL_NAME = \"\"  # FOR EXAMPLE: \"trained_model_monet_blocks.h5\"\n"
      ],
      "metadata": {
        "id": "hoeWuTISbhf5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**For running training process - please fill the following globals**\n"
      ],
      "metadata": {
        "id": "xUnq3OWAlf38"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# For running training process - please fill the following globals\n",
        "MASKS_TO_TRAIN = \"\"  # FOR EXAMPLE: \"all\" or \"center\" or \"blocks\" or \"region\"\n",
        "TRAIN_PATH = \"\"  # FOR EXAMPLE: \"./train_photos\" or \"./train_preview\"\n",
        "VALID_PATH = \"\"  # FOR EXAMPLE: \"./valid_photos\" or \"./valid_preview\"\n",
        "ARBITRARY_MASK_PATH = \"\"    #FOR EXAMPLE: \"./arbi\""
      ],
      "metadata": {
        "id": "g5x8PBU-la_G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for 'Photos' dataset**"
      ],
      "metadata": {
        "id": "eUg514A8bpHG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports:\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv2DTranspose, Conv2D, \\\n",
        "    MaxPooling2D, Activation, BatchNormalization, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "# globals:\n",
        "IMG_SIZE = 128\n",
        "MASK_SIZE = 128\n",
        "RGB_DIM = 3\n",
        "EPOCHS = 300\n",
        "IMAGE_SHAPE = (IMG_SIZE, IMG_SIZE, RGB_DIM)\n",
        "MISS_SHAPE = (MASK_SIZE, MASK_SIZE, RGB_DIM)\n",
        "LAMBDA_RECON = 0.999\n",
        "LAMBDA_ADVR = 0.001\n",
        "OPTIMIZER = Adam(0.0002, 0.5)\n",
        "BATCH_SIZE = 64\n",
        "DISC_OUTPUT_SIZE = 14\n",
        "MIN_RANDOM_BLOCKS_AMOUNT = 3\n",
        "MAX_RANDOM_BLOCKS_AMOUNT = 9\n",
        "RANDOM_BLOCK_SIZE = 21\n",
        "MIN_VALID_TOTAL_LOSS = sys.maxsize\n",
        "arbitrary_masks = []\n",
        "inverse_arbitrary_masks = []\n",
        "valid_total_loss = []\n",
        "train_total_loss = []\n",
        "\n",
        "\n",
        "# The function inits discriminator according to the patch gan arcithecture\n",
        "def init_discriminator_patch_gan():\n",
        "    model = Sequential()\n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=MISS_SHAPE, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(tf.keras.layers.ZeroPadding2D())\n",
        "\n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(512, kernel_size=4, strides=1, padding=\"valid\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(tf.keras.layers.ZeroPadding2D())\n",
        "\n",
        "    model.add(Conv2D(1, kernel_size=4, strides=1, padding=\"valid\", activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=MISS_SHAPE)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "\n",
        "# The function inits the generator\n",
        "def init_generator():\n",
        "    model = Sequential()\n",
        "    init_encoder(model)\n",
        "    init_decoder(model)\n",
        "    model.summary()\n",
        "    masked_img = Input(shape=IMAGE_SHAPE)\n",
        "    gen_pred = model(masked_img)\n",
        "\n",
        "    return Model(masked_img, gen_pred)\n",
        "\n",
        "\n",
        "# The function inits the encoder\n",
        "def init_encoder(model):\n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(filters=96, input_shape=(128, 128, 3), kernel_size=(11, 11), strides=(4, 4)))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(5, 5), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(filters=384, kernel_size=(3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(filters=256, kernel_size=(3, 3), padding='same'))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('relu'))\n",
        "\n",
        "    # Pooling\n",
        "    model.add(MaxPooling2D(pool_size=(3, 3), strides=(2, 2)))\n",
        "\n",
        "    # Passing it to a dense layer\n",
        "    model.add(Flatten())\n",
        "\n",
        "    # 1st Dense Layer\n",
        "    model.add(Dense(9216, input_shape=(128 * 128 * 3,)))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(Dropout(0.4))\n",
        "\n",
        "\n",
        "# The function inits the decoder\n",
        "def init_decoder(model):\n",
        "    first_layer = Reshape((6, 6, 256))\n",
        "    model.add(first_layer)\n",
        "\n",
        "    # 1st Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "\n",
        "    # 2nd Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 3rd Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 4th Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(32, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 5th Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(RGB_DIM, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    last_layer = Resizing(IMG_SIZE, IMG_SIZE)\n",
        "    model.add(last_layer)\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "\n",
        "# The function inits the full context encoder\n",
        "def init_contextEncoder():\n",
        "    # inits and compiles the discriminator\n",
        "    discriminator = init_discriminator_patch_gan()\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=OPTIMIZER,\n",
        "                          metrics=['accuracy'])\n",
        "    # inits the generator\n",
        "    generator = init_generator()\n",
        "    masked_img = Input(shape=IMAGE_SHAPE)\n",
        "    gen_pred = generator(masked_img)\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    real = discriminator(gen_pred)\n",
        "\n",
        "    combined = Model(masked_img, [gen_pred, real])\n",
        "    combined.compile(loss=['mse', 'binary_crossentropy'],\n",
        "                     loss_weights=[LAMBDA_RECON, LAMBDA_ADVR],\n",
        "                     optimizer=OPTIMIZER)\n",
        "\n",
        "    return generator, discriminator, combined\n",
        "\n",
        "\n",
        "# The function creates center mask for image\n",
        "def create_center_mask(photo):\n",
        "    photo = photo.numpy()\n",
        "    masked_img = photo.copy()\n",
        "    masked_img_copy = photo.copy()\n",
        "    missing_part = photo.copy()\n",
        "    mask = photo.copy()\n",
        "    x1 = y1 = int(IMG_SIZE / 4)  # 32\n",
        "    x2 = y2 = int((IMG_SIZE / 4) * 3)  # 96\n",
        "\n",
        "    missing_part[:] = 1\n",
        "    missing_part[y1:y2, x1:x2, :] = masked_img_copy[y1:y2, x1:x2, :].copy()\n",
        "    mask[:] = 0\n",
        "    mask[y1:y2, x1:x2, :] = 1\n",
        "    masked_img[y1:y2, x1:x2, :] = 0\n",
        "\n",
        "    return masked_img, missing_part, photo, mask\n",
        "\n",
        "\n",
        "# The function creates random blocks mask for image\n",
        "def create_random_blocks_mask(photo):\n",
        "    photo = photo.numpy()\n",
        "    masked_img = photo.copy()\n",
        "    masked_img_copy = photo.copy()\n",
        "    missing_part = photo.copy()\n",
        "    missing_part[:] = 1\n",
        "    mask = photo.copy()\n",
        "    mask[:] = 0\n",
        "    blocks_amount = random.randint(MIN_RANDOM_BLOCKS_AMOUNT, MAX_RANDOM_BLOCKS_AMOUNT)\n",
        "    for i in range(blocks_amount):\n",
        "        y1 = random.randint(0, IMG_SIZE - RANDOM_BLOCK_SIZE)  # (0, 107)\n",
        "        y2 = y1 + RANDOM_BLOCK_SIZE\n",
        "        x1 = random.randint(0, IMG_SIZE - RANDOM_BLOCK_SIZE)  # (0, 107)\n",
        "        x2 = x1 + RANDOM_BLOCK_SIZE\n",
        "\n",
        "        missing_part[y1:y2, x1:x2, :] = masked_img_copy[y1:y2, x1:x2, :].copy()\n",
        "        mask[y1:y2, x1:x2, :] = 1\n",
        "        masked_img[y1:y2, x1:x2, :] = 0\n",
        "\n",
        "    return masked_img, missing_part, photo, mask\n",
        "\n",
        "\n",
        "# The function creates arbitrary mask for image\n",
        "def create_arbitrary_mask(photo):\n",
        "    global arbitrary_masks, inverse_arbitrary_masks\n",
        "\n",
        "    arbi_mask_idx = np.random.randint(0, len(arbitrary_masks))\n",
        "    arbitrary_mask = arbitrary_masks[arbi_mask_idx]\n",
        "    inverse_arbitrary_mask = inverse_arbitrary_masks[arbi_mask_idx]\n",
        "\n",
        "    masked_img = np.multiply(inverse_arbitrary_mask, photo)\n",
        "    missing_part = np.multiply(arbitrary_mask, photo)\n",
        "\n",
        "    return masked_img, missing_part, photo, arbitrary_mask\n",
        "\n",
        "\n",
        "# The function creates and returns the inverse mask\n",
        "def get_arbitrary_mask():\n",
        "    global arbitrary_masks, inverse_arbitrary_masks\n",
        "    masks_photos_list = os.listdir(ARBITRARY_MASK_PATH + \"/\")\n",
        "    for mask in masks_photos_list:\n",
        "        arbitrary_mask_name = ARBITRARY_MASK_PATH + \"/\" + mask\n",
        "        arbi_mask = Image.open(arbitrary_mask_name).convert(\"L\")\n",
        "        arbi_mask = arbi_mask.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
        "        arbi_mask = np.asarray(arbi_mask)\n",
        "        arbi_mask, inverse_arbi_mask = get_inverse_mask(arbi_mask)\n",
        "\n",
        "        dim1 = np.zeros((IMG_SIZE, IMG_SIZE))\n",
        "        dim2 = np.add(dim1, arbi_mask)\n",
        "        arbitrary_mask_3d = np.stack((arbi_mask, dim2, dim2), axis=2)\n",
        "\n",
        "        dim3 = np.zeros((IMG_SIZE, IMG_SIZE))\n",
        "        dim4 = np.add(dim3, inverse_arbi_mask)\n",
        "        inverse_arbitrary_mask_3d = np.stack((inverse_arbi_mask, dim4, dim4), axis=2)\n",
        "\n",
        "        arbitrary_masks.append(arbitrary_mask_3d)\n",
        "        inverse_arbitrary_masks.append(inverse_arbitrary_mask_3d)\n",
        "\n",
        "    arbitrary_masks = np.asarray(arbitrary_masks)\n",
        "    inverse_arbitrary_masks = np.asarray(inverse_arbitrary_masks)\n",
        "\n",
        "\n",
        "# The function makes the same shuffle to train_x and train_y and train_z\n",
        "def shuffle_data(train_x, train_y, train_z):\n",
        "    shuffler = np.random.permutation(len(train_x))\n",
        "    train_x_shuffled = train_x[shuffler]\n",
        "    train_y_shuffled = train_y[shuffler]\n",
        "    train_z_shuffled = train_z[shuffler]\n",
        "    return train_x_shuffled, train_y_shuffled, train_z_shuffled\n",
        "\n",
        "\n",
        "# The function loads data\n",
        "def load_data(photos_path):\n",
        "    photos_list = os.listdir(photos_path)  # e.g. \"./train_photos\"\n",
        "\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "        layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)\n",
        "        , layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "    ])\n",
        "\n",
        "    masked_imgs = []\n",
        "    missing_parts = []\n",
        "    photos = []\n",
        "    masks = []\n",
        "\n",
        "    shuffle(photos_list)\n",
        "\n",
        "    for photo in photos_list:\n",
        "        sample_photo = plt.imread(os.path.join(photos_path, photo))\n",
        "        edited_photo = resize_and_rescale(sample_photo)\n",
        "        if MASKS_TO_TRAIN == \"all\":\n",
        "            mask_idx = random.randint(0, 2)\n",
        "            if mask_idx == 0:\n",
        "                masked_img, missing_part, photo, mask = create_center_mask(edited_photo)\n",
        "            elif mask_idx == 1:\n",
        "                masked_img, missing_part, photo, mask = create_random_blocks_mask(edited_photo)\n",
        "            else:\n",
        "                masked_img, missing_part, photo, mask = create_arbitrary_mask(edited_photo)\n",
        "        elif MASKS_TO_TRAIN == \"center\":\n",
        "            masked_img, missing_part, photo, mask = create_center_mask(edited_photo)\n",
        "        elif MASKS_TO_TRAIN == \"blocks\":\n",
        "            masked_img, missing_part, photo, mask = create_random_blocks_mask(edited_photo)\n",
        "        else:\n",
        "            masked_img, missing_part, photo, mask = create_arbitrary_mask(edited_photo)\n",
        "        masked_imgs.append(masked_img)\n",
        "        missing_parts.append(missing_part)\n",
        "        photos.append(photo)\n",
        "        masks.append(mask)\n",
        "\n",
        "    masked_imgs = np.asarray(masked_imgs)\n",
        "    missing_parts = np.asarray(missing_parts)\n",
        "    photos = np.asarray(photos)\n",
        "    masks = np.asarray(masks)\n",
        "\n",
        "    return masked_imgs, missing_parts, photos, masks\n",
        "\n",
        "\n",
        "# The function creates and returns the inverse mask\n",
        "def get_inverse_mask(arbitrary_mask):\n",
        "    inverse_arbitrary_mask_2d = np.copy(arbitrary_mask)\n",
        "    arbitrary_mask_2d = np.copy(arbitrary_mask)\n",
        "    for i in range(IMG_SIZE):\n",
        "        for j in range(IMG_SIZE):\n",
        "            if inverse_arbitrary_mask_2d[i][j] != 0:\n",
        "                inverse_arbitrary_mask_2d[i][j] = 0\n",
        "                arbitrary_mask_2d[i][j] = 1\n",
        "            else:\n",
        "                inverse_arbitrary_mask_2d[i][j] = 1\n",
        "                arbitrary_mask_2d[i][j] = 0\n",
        "    return arbitrary_mask_2d, inverse_arbitrary_mask_2d\n",
        "\n",
        "\n",
        "# The function tests on the validation set\n",
        "def test(generator, masked_imgs_valid, missing_parts_valid, photos_valid, masks_valid, batch_size):\n",
        "    masked_imgs_valid = masked_imgs_valid[:batch_size]\n",
        "    missing_parts_valid = missing_parts_valid[:batch_size]\n",
        "    photos_valid = photos_valid[:batch_size]\n",
        "    masks_valid = masks_valid[:batch_size]\n",
        "    gen_pred_valid = generator.predict(masked_imgs_valid)\n",
        "    y_hat_multi_mask = np.multiply(gen_pred_valid, masks_valid)\n",
        "    filled_imgs_valid = np.add(y_hat_multi_mask, masked_imgs_valid)\n",
        "    for i in range(7):\n",
        "        f, ax = plt.subplots(1, 6, figsize=(25, 25))\n",
        "        ax[0].imshow(photos_valid[i])\n",
        "        ax[0].set_title(\"photo_valid\")\n",
        "        ax[1].imshow(masked_imgs_valid[i])\n",
        "        ax[1].set_title(\"masked_imgs\")\n",
        "        ax[2].imshow(gen_pred_valid[i])\n",
        "        ax[2].set_title(\"gen_pred valid\")\n",
        "        ax[3].imshow(missing_parts_valid[i])\n",
        "        ax[3].set_title(\"missing_part\")\n",
        "        ax[4].imshow(y_hat_multi_mask[i])\n",
        "        ax[4].set_title(\"y_hat_multi_mask\")\n",
        "        ax[5].imshow(filled_imgs_valid[i])\n",
        "        ax[5].set_title(\"filled_imgs_valid2\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# The function tests on the validation set\n",
        "def test_on_batch(combined_model, masked_imgs_valid, photos_valid, valid, epoch):\n",
        "    global valid_total_loss, train_total_loss\n",
        "    masked_imgs_valid_tmp = masked_imgs_valid\n",
        "    photos_valid_tmp = photos_valid\n",
        "    batches_amount = int(len(masked_imgs_valid) / BATCH_SIZE) - 1\n",
        "    sum_total_loss_valid = 0\n",
        "    for i in range(batches_amount):\n",
        "        batch_size_start = BATCH_SIZE * i\n",
        "        batch_size_end = batch_size_start + BATCH_SIZE\n",
        "        masked_imgs_valid_batch = masked_imgs_valid_tmp[batch_size_start:batch_size_end]\n",
        "        photos_valid_batch = photos_valid_tmp[batch_size_start:batch_size_end]\n",
        "        g_valid_loss = combined_model.test_on_batch(masked_imgs_valid_batch, [photos_valid_batch, valid])\n",
        "        sum_total_loss_valid += g_valid_loss[0]\n",
        "\n",
        "        print(\"%d , valid_loss_1: %f , valid_loss_2: %f\" % (epoch, g_valid_loss[0], g_valid_loss[1]))\n",
        "\n",
        "    avg_total_loss = sum_total_loss_valid / batches_amount\n",
        "    valid_total_loss.append(avg_total_loss)\n",
        "    # Plot the validation progress\n",
        "    if epoch % 5 == 0:\n",
        "        show_train_and_valid_graph()\n",
        "\n",
        "\n",
        "# The function presents graphic results\n",
        "def show_train_and_valid_graph():\n",
        "    plt.title('Model Total Loss')\n",
        "    plt.ylabel('Total loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.plot(valid_total_loss, label=\"valid\")\n",
        "    plt.plot(train_total_loss, label=\"train\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# The function trains the model\n",
        "def train(combined_model, generator, discriminator, masked_imgs_train, missing_parts_train, masked_imgs_valid,\n",
        "          missing_parts_valid, photos_train, photos_valid, masks_train, masks_valid, epochs, batch_size):\n",
        "    global train_total_loss\n",
        "    batches_amount = int(len(masked_imgs_train) / BATCH_SIZE) - 1\n",
        "    real = np.ones((batch_size, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE, 1))  # (64, 14, 14, 1)\n",
        "    fake = np.zeros((batch_size, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE, 1))  # (64, 14, 14, 1)\n",
        "    for epoch in range(epochs):\n",
        "        sum_total_loss_train = 0\n",
        "        # train discriminator\n",
        "        masked_imgs_train_shuff, missing_parts_train_shuff, photos_train_shuff = shuffle_data(masked_imgs_train,\n",
        "                                                                                              missing_parts_train,\n",
        "                                                                                              photos_train)\n",
        "        masked_imgs_train_tmp = masked_imgs_train_shuff\n",
        "        photos_train_tmp = photos_train_shuff\n",
        "        for i in range(batches_amount):\n",
        "            batch_size_start = BATCH_SIZE * i\n",
        "            batch_size_end = batch_size_start + BATCH_SIZE\n",
        "            masked_imgs = masked_imgs_train_tmp[batch_size_start:batch_size_end]\n",
        "            photos_train_batch = photos_train_tmp[batch_size_start:batch_size_end]\n",
        "\n",
        "            # the prediction result\n",
        "            gen_pred = generator.predict(masked_imgs)\n",
        "\n",
        "            # Train the discriminator\n",
        "            d_loss_real = discriminator.train_on_batch(photos_train_batch, real)\n",
        "            d_loss_fake = discriminator.train_on_batch(gen_pred, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Train the Generator\n",
        "            g_loss = combined_model.train_on_batch(masked_imgs, [photos_train_batch, real])\n",
        "\n",
        "            sum_total_loss_train += g_loss[0]\n",
        "\n",
        "            print(\" Epoch:%d -- Discrimnator loss: %f -- Accuracy: %.2f%% -- Generator loss: %f -- Mse: %f\" % (\n",
        "                epoch, d_loss[0], 100 * d_loss[1], g_loss[0], g_loss[1]))\n",
        "\n",
        "        avg_total_loss = sum_total_loss_train / batches_amount\n",
        "        train_total_loss.append(avg_total_loss)\n",
        "\n",
        "        test(generator, masked_imgs_valid, missing_parts_valid, photos_valid, masks_valid, batch_size)\n",
        "        test_on_batch(combined_model, masked_imgs_valid, photos_valid, real, epoch)\n",
        "        save_best_model(generator, epoch)\n",
        "\n",
        "\n",
        "# The function loads the best model found\n",
        "def load_best_model(masked_imgs_valid, photos_valid, masks_valid):\n",
        "    model = keras.models.load_model(\"best_model.h5\")\n",
        "    masked_imgs_valid = masked_imgs_valid[:BATCH_SIZE]\n",
        "    photos_valid = photos_valid[:BATCH_SIZE]\n",
        "    masks_valid = masks_valid[:BATCH_SIZE]\n",
        "    gen_pred_valid = model.predict(masked_imgs_valid)\n",
        "    y_hat_multi_mask = np.multiply(gen_pred_valid, masks_valid)\n",
        "    filled_imgs_valid = np.add(y_hat_multi_mask, masked_imgs_valid)\n",
        "    print(\"inside test: \")\n",
        "    for i in range(7):\n",
        "        f, ax = plt.subplots(1, 5, figsize=(25, 25))\n",
        "        ax[0].imshow(photos_valid[i])\n",
        "        ax[0].set_title(\"photo_valid\")\n",
        "        ax[1].imshow(masked_imgs_valid[i])\n",
        "        ax[1].set_title(\"masked_imgs\")\n",
        "        ax[2].imshow(gen_pred_valid[i])\n",
        "        ax[2].set_title(\"gen_pred_valid\")\n",
        "        ax[3].imshow(y_hat_multi_mask[i])\n",
        "        ax[3].set_title(\"y_hat_multi_mask\")\n",
        "        ax[4].imshow(filled_imgs_valid[i])\n",
        "        ax[4].set_title(\"filled_imgs_valid2\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# The function saves the best model found\n",
        "def save_best_model(model, epoch):\n",
        "    global MIN_VALID_TOTAL_LOSS\n",
        "    if valid_total_loss[epoch] < MIN_VALID_TOTAL_LOSS:\n",
        "        MIN_VALID_TOTAL_LOSS = valid_total_loss[epoch]\n",
        "        print(\"----------------------------------------- saved model ------------------------------------------\")\n",
        "        model.save(\"best_model.h5\")\n",
        "\n",
        "\n",
        "def test_data():\n",
        "    dir_name = DATA_PATH\n",
        "    dir_list = os.listdir(dir_name)\n",
        "    dir_list = sorted(dir_list)\n",
        "\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "        layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)\n",
        "        , layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "    ])\n",
        "\n",
        "    masked_imgs_valid = []\n",
        "    photos_valid = []\n",
        "    masks_valid = []\n",
        "\n",
        "    for idx, item in enumerate(dir_list):\n",
        "        if item == \".DS_Store\":\n",
        "            continue\n",
        "        if idx % 2 == 0:\n",
        "            if dir_name == \"./test/photos_region\":\n",
        "                photo_path = dir_name + \"/\" + dir_list[idx - 1]\n",
        "                mask_path = dir_name + \"/\" + dir_list[idx]\n",
        "            elif dir_name == \"./test/photos_blocks\" or dir_name == \"./test/monet_central_block\" or dir_name == \"./test/monet_blocks\":\n",
        "                photo_path = dir_name + \"/\" + dir_list[idx]\n",
        "                mask_path = dir_name + \"/\" + dir_list[idx - 1]\n",
        "            else:\n",
        "                photo_path = dir_name + \"/\" + dir_list[idx - 1]\n",
        "                mask_path = dir_name + \"/\" + dir_list[idx]\n",
        "            photo = plt.imread(photo_path)\n",
        "            edited_photo = resize_and_rescale(photo)\n",
        "            mask = plt.imread(mask_path)\n",
        "            edited_mask = resize_and_rescale(mask)\n",
        "            edited_photo = edited_photo - edited_mask\n",
        "            masked_imgs_valid.append(edited_photo)\n",
        "            photos_valid.append(edited_photo)\n",
        "            masks_valid.append(edited_mask)\n",
        "\n",
        "    masked_imgs_valid = np.asarray(masked_imgs_valid)\n",
        "    photos_valid = np.asarray(photos_valid)\n",
        "    masks_valid = np.asarray(masks_valid)\n",
        "\n",
        "    model = keras.models.load_model(TRAINED_MODEL_NAME)\n",
        "    gen_pred_valid = model.predict(masked_imgs_valid)\n",
        "    gen_pred_valid = np.asarray(gen_pred_valid)\n",
        "    y_hat_multi_mask = np.multiply(gen_pred_valid, masks_valid)\n",
        "    filled_imgs_valid = np.add(y_hat_multi_mask, masked_imgs_valid)\n",
        "    for i in range(len(masked_imgs_valid)):\n",
        "        f, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "        ax[0].imshow(masked_imgs_valid[i])\n",
        "        ax[1].imshow(filled_imgs_valid[i])\n",
        "        plt.show()\n"
      ],
      "metadata": {
        "id": "7gurjz3LbbuR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Code for 'Monet' dataset**"
      ],
      "metadata": {
        "id": "miyjFcaLb26o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# imports:\n",
        "import os\n",
        "import sys\n",
        "import random\n",
        "import numpy as np\n",
        "from random import shuffle\n",
        "from PIL import Image\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Dropout, Conv2DTranspose, Conv2D, \\\n",
        "    MaxPooling2D, Activation, BatchNormalization, ZeroPadding2D\n",
        "from keras.layers.advanced_activations import LeakyReLU\n",
        "from keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Resizing\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow import keras\n",
        "\n",
        "# globals:\n",
        "IMG_SIZE = 128\n",
        "MASK_SIZE = 128\n",
        "RGB_DIM = 3\n",
        "EPOCHS = 300\n",
        "IMAGE_SHAPE = (IMG_SIZE, IMG_SIZE, RGB_DIM)\n",
        "MISS_SHAPE = (MASK_SIZE, MASK_SIZE, RGB_DIM)\n",
        "LAMBDA_RECON = 0.999\n",
        "LAMBDA_ADVR = 0.001\n",
        "LAMBDA_STYLE = 0.01\n",
        "OPTIMIZER = Adam(0.0002, 0.5)\n",
        "BATCH_SIZE = 64\n",
        "DISC_OUTPUT_SIZE = 14\n",
        "MIN_RANDOM_BLOCKS_AMOUNT = 3\n",
        "MAX_RANDOM_BLOCKS_AMOUNT = 9\n",
        "RANDOM_BLOCK_SIZE = 21\n",
        "MIN_VALID_TOTAL_LOSS = sys.maxsize\n",
        "arbitrary_masks = []\n",
        "inverse_arbitrary_masks = []\n",
        "valid_total_loss = []\n",
        "train_total_loss = []\n",
        "layers_output = dict()\n",
        "feature_extractor = None\n",
        "\n",
        "\n",
        "# The function calcculate the gram matrix\n",
        "def get_gram_matrix(input_x):\n",
        "    input_x = tf.transpose(input_x, (2, 0, 1))\n",
        "    features = tf.reshape(input_x, (tf.shape(input_x)[0], -1))\n",
        "    gram = tf.matmul(features, tf.transpose(features))\n",
        "    return gram\n",
        "\n",
        "\n",
        "# The function calculate the style loss for one layer\n",
        "def get_style_loss(style_features, pred_features):\n",
        "    style_gram_matrix = get_gram_matrix(style_features)\n",
        "    original_gram_matrix = get_gram_matrix(pred_features)\n",
        "    size = IMG_SIZE * IMG_SIZE\n",
        "    return tf.reduce_sum(tf.square(style_gram_matrix - original_gram_matrix)) / (4.0 * (RGB_DIM ** 2) * (size ** 2))\n",
        "\n",
        "\n",
        "# The function return the style loss for all layers\n",
        "def style_loss(y_true, y_pred):\n",
        "    combined_y = tf.concat([y_true, y_pred], axis=0)\n",
        "    features = feature_extractor(combined_y)\n",
        "    style_loss_val = tf.zeros(shape=())\n",
        "\n",
        "    # extract the style loss from the generator layers\n",
        "    for layer_name in layers_output:\n",
        "        layer_features = features[layer_name]\n",
        "        style_features = layer_features[0, :, :, :]\n",
        "        pred_features = layer_features[1, :, :, :]\n",
        "        layer_style_loss = get_style_loss(style_features, pred_features)\n",
        "        style_loss_val += (1 / len(layers_output)) * layer_style_loss\n",
        "\n",
        "    return style_loss_val\n",
        "\n",
        "\n",
        "# The function inits discriminator according to the patch gan architecture\n",
        "def init_discriminator_patch_gan():\n",
        "    model = Sequential()\n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=MISS_SHAPE, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "\n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(tf.keras.layers.ZeroPadding2D())\n",
        "\n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(512, kernel_size=4, strides=1, padding=\"valid\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    model.add(tf.keras.layers.ZeroPadding2D())\n",
        "\n",
        "    model.add(Conv2D(1, kernel_size=4, strides=1, padding=\"valid\", activation='sigmoid'))\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    img = Input(shape=MISS_SHAPE)\n",
        "    validity = model(img)\n",
        "\n",
        "    return Model(img, validity)\n",
        "\n",
        "\n",
        "# The function init generator with 4 convolution layers and patch gan\n",
        "def init_generator():\n",
        "    global layers_output, feature_extractor\n",
        "    model = Sequential()\n",
        "    init_encoder(model)\n",
        "\n",
        "    layers_output = dict([(layer.name, layer.output) for layer in model.layers])\n",
        "    feature_extractor = Model(inputs=model.inputs, outputs=layers_output)\n",
        "\n",
        "    # bottleneck\n",
        "    model.add(Conv2D(4000, kernel_size=4, strides=1, padding=\"valid\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    init_decoder(model)\n",
        "\n",
        "    model.summary()\n",
        "\n",
        "    masked_img = Input(shape=IMAGE_SHAPE)\n",
        "    gen_pred = model(masked_img)\n",
        "\n",
        "    return Model(masked_img, gen_pred)\n",
        "\n",
        "\n",
        "# The function inits the encoder\n",
        "def init_encoder(model):\n",
        "    # 1st Convolutional Layer\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, input_shape=IMAGE_SHAPE, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 2nd Convolutional Layer\n",
        "    model.add(Conv2D(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 3rd Convolutional Layer\n",
        "    model.add(Conv2D(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 4th Convolutional Layer\n",
        "    model.add(Conv2D(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # 5th Convolutional Layer\n",
        "    model.add(Conv2D(512, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "    # 6th Convolutional Layer\n",
        "    model.add(Conv2D(512, kernel_size=4, strides=1, padding=\"same\"))\n",
        "    model.add(LeakyReLU(alpha=0.2))\n",
        "    model.add(Dropout(0.5))\n",
        "\n",
        "\n",
        "# The function inits  the decoder\n",
        "def init_decoder(model):\n",
        "    # 1st Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"))\n",
        "\n",
        "    # 2nd Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 3rd Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(512, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 4th Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(256, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 5th Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(128, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 6th Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(64, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('relu'))\n",
        "    model.add(BatchNormalization(momentum=0.8))\n",
        "\n",
        "    # 7th Up-Convolutional Layer\n",
        "    model.add(Conv2DTranspose(RGB_DIM, kernel_size=4, strides=2, padding=\"same\"))\n",
        "    model.add(Activation('tanh'))\n",
        "\n",
        "\n",
        "# The function init the full context encoder\n",
        "def init_contextEncoder():\n",
        "    # init and compile the discriminator\n",
        "    discriminator = init_discriminator_patch_gan()\n",
        "    discriminator.compile(loss='binary_crossentropy',\n",
        "                          optimizer=OPTIMIZER,\n",
        "                          metrics=['accuracy'])\n",
        "    # init the generator\n",
        "    generator = init_generator()\n",
        "    masked_img = Input(shape=IMAGE_SHAPE)\n",
        "    gen_pred = generator(masked_img)\n",
        "\n",
        "    discriminator.trainable = False\n",
        "\n",
        "    real = discriminator(gen_pred)\n",
        "\n",
        "    combined = Model(masked_img, [gen_pred, real])\n",
        "    combined.compile(loss=['mse', 'binary_crossentropy', style_loss],\n",
        "                     loss_weights=[LAMBDA_RECON, LAMBDA_ADVR, LAMBDA_STYLE],\n",
        "                     optimizer=OPTIMIZER)\n",
        "\n",
        "    return generator, discriminator, combined\n",
        "\n",
        "\n",
        "# The function creates center mask for image\n",
        "def create_center_mask(photo):\n",
        "    photo = photo.numpy()\n",
        "    masked_img = photo.copy()\n",
        "    masked_img_copy = photo.copy()\n",
        "    missing_part = photo.copy()\n",
        "    mask = photo.copy()\n",
        "    x1 = y1 = int(IMG_SIZE / 4)  # 32\n",
        "    x2 = y2 = int((IMG_SIZE / 4) * 3)  # 96\n",
        "\n",
        "    missing_part[:] = 1\n",
        "    missing_part[y1:y2, x1:x2, :] = masked_img_copy[y1:y2, x1:x2, :].copy()\n",
        "    mask[:] = 0\n",
        "    mask[y1:y2, x1:x2, :] = 1\n",
        "    masked_img[y1:y2, x1:x2, :] = 0\n",
        "\n",
        "    return masked_img, missing_part, photo, mask\n",
        "\n",
        "\n",
        "# The function creates random blocks mask for image\n",
        "def create_random_blocks_mask(photo):\n",
        "    photo = photo.numpy()\n",
        "    masked_img = photo.copy()\n",
        "    masked_img_copy = photo.copy()\n",
        "    missing_part = photo.copy()\n",
        "    missing_part[:] = 1\n",
        "    mask = photo.copy()\n",
        "    mask[:] = 0\n",
        "    blocks_amount = random.randint(MIN_RANDOM_BLOCKS_AMOUNT, MAX_RANDOM_BLOCKS_AMOUNT)\n",
        "    for i in range(blocks_amount):\n",
        "        y1 = random.randint(0, IMG_SIZE - RANDOM_BLOCK_SIZE)  # (0, 107)\n",
        "        y2 = y1 + RANDOM_BLOCK_SIZE\n",
        "        x1 = random.randint(0, IMG_SIZE - RANDOM_BLOCK_SIZE)  # (0, 107)\n",
        "        x2 = x1 + RANDOM_BLOCK_SIZE\n",
        "\n",
        "        missing_part[y1:y2, x1:x2, :] = masked_img_copy[y1:y2, x1:x2, :].copy()\n",
        "        mask[y1:y2, x1:x2, :] = 1\n",
        "        masked_img[y1:y2, x1:x2, :] = 0\n",
        "\n",
        "    return masked_img, missing_part, photo, mask\n",
        "\n",
        "\n",
        "# The function creates arbitrary mask for image\n",
        "def create_arbitrary_mask(photo):\n",
        "    global arbitrary_masks, inverse_arbitrary_masks\n",
        "\n",
        "    arbi_mask_idx = np.random.randint(0, len(arbitrary_masks))\n",
        "    arbitrary_mask = arbitrary_masks[arbi_mask_idx]\n",
        "    inverse_arbitrary_mask = inverse_arbitrary_masks[arbi_mask_idx]\n",
        "\n",
        "    masked_img = np.multiply(inverse_arbitrary_mask, photo)\n",
        "    missing_part = np.multiply(arbitrary_mask, photo)\n",
        "\n",
        "    return masked_img, missing_part, photo, arbitrary_mask\n",
        "\n",
        "\n",
        "# The function creates and returns the inverse mask\n",
        "def get_arbitrary_mask():\n",
        "    global arbitrary_masks, inverse_arbitrary_masks\n",
        "    masks_photos_list = os.listdir(ARBITRARY_MASK_PATH + \"/\")\n",
        "    for mask in masks_photos_list:\n",
        "        arbitrary_mask_name = ARBITRARY_MASK_PATH + \"/\" + mask\n",
        "        arbi_mask = Image.open(arbitrary_mask_name).convert(\"L\")\n",
        "        arbi_mask = arbi_mask.resize((IMG_SIZE, IMG_SIZE), Image.ANTIALIAS)\n",
        "        arbi_mask = np.asarray(arbi_mask)\n",
        "        arbi_mask, inverse_arbi_mask = get_inverse_mask(arbi_mask)\n",
        "\n",
        "        dim1 = np.zeros((IMG_SIZE, IMG_SIZE))\n",
        "        dim2 = np.add(dim1, arbi_mask)\n",
        "        arbitrary_mask_3d = np.stack((arbi_mask, dim2, dim2), axis=2)\n",
        "\n",
        "        dim3 = np.zeros((IMG_SIZE, IMG_SIZE))\n",
        "        dim4 = np.add(dim3, inverse_arbi_mask)\n",
        "        inverse_arbitrary_mask_3d = np.stack((inverse_arbi_mask, dim4, dim4), axis=2)\n",
        "\n",
        "        arbitrary_masks.append(arbitrary_mask_3d)\n",
        "        inverse_arbitrary_masks.append(inverse_arbitrary_mask_3d)\n",
        "\n",
        "    arbitrary_masks = np.asarray(arbitrary_masks)\n",
        "    inverse_arbitrary_masks = np.asarray(inverse_arbitrary_masks)\n",
        "\n",
        "\n",
        "\n",
        "# The function makes the same shuffle to train_x and train_y and train_z\n",
        "def shuffle_data(train_x, train_y, train_z):\n",
        "    shuffler = np.random.permutation(len(train_x))\n",
        "    train_x_shuffled = train_x[shuffler]\n",
        "    train_y_shuffled = train_y[shuffler]\n",
        "    train_z_shuffled = train_z[shuffler]\n",
        "    return train_x_shuffled, train_y_shuffled, train_z_shuffled\n",
        "\n",
        "\n",
        "# The function loads data\n",
        "def load_data(photos_path):\n",
        "    photos_list = os.listdir(photos_path)  # e.g. \"./train_photos\"\n",
        "\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "        layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)\n",
        "        , layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "    ])\n",
        "\n",
        "    masked_imgs = []\n",
        "    missing_parts = []\n",
        "    photos = []\n",
        "    masks = []\n",
        "\n",
        "    shuffle(photos_list)\n",
        "\n",
        "    for photo in photos_list:\n",
        "        sample_photo = plt.imread(os.path.join(photos_path, photo))\n",
        "        edited_photo = resize_and_rescale(sample_photo)\n",
        "        if MASKS_TO_TRAIN == \"all\":\n",
        "            mask_idx = random.randint(0, 2)\n",
        "            if mask_idx == 0:\n",
        "                masked_img, missing_part, photo, mask = create_center_mask(edited_photo)\n",
        "            elif mask_idx == 1:\n",
        "                masked_img, missing_part, photo, mask = create_random_blocks_mask(edited_photo)\n",
        "            else:\n",
        "                masked_img, missing_part, photo, mask = create_arbitrary_mask(edited_photo)\n",
        "        elif MASKS_TO_TRAIN == \"center\":\n",
        "            masked_img, missing_part, photo, mask = create_center_mask(edited_photo)\n",
        "        elif MASKS_TO_TRAIN == \"blocks\":\n",
        "            masked_img, missing_part, photo, mask = create_random_blocks_mask(edited_photo)\n",
        "        else:\n",
        "            masked_img, missing_part, photo, mask = create_arbitrary_mask(edited_photo)\n",
        "        masked_imgs.append(masked_img)\n",
        "        missing_parts.append(missing_part)\n",
        "        photos.append(photo)\n",
        "        masks.append(mask)\n",
        "\n",
        "    masked_imgs = np.asarray(masked_imgs)\n",
        "    missing_parts = np.asarray(missing_parts)\n",
        "    photos = np.asarray(photos)\n",
        "    masks = np.asarray(masks)\n",
        "\n",
        "    return masked_imgs, missing_parts, photos, masks\n",
        "\n",
        "\n",
        "# The function creates and returns the inverse mask\n",
        "def get_inverse_mask(arbitrary_mask):\n",
        "    inverse_arbitrary_mask_2d = np.copy(arbitrary_mask)\n",
        "    arbitrary_mask_2d = np.copy(arbitrary_mask)\n",
        "    for i in range(IMG_SIZE):\n",
        "        for j in range(IMG_SIZE):\n",
        "            if inverse_arbitrary_mask_2d[i][j] != 0:\n",
        "                inverse_arbitrary_mask_2d[i][j] = 0\n",
        "                arbitrary_mask_2d[i][j] = 1\n",
        "            else:\n",
        "                inverse_arbitrary_mask_2d[i][j] = 1\n",
        "                arbitrary_mask_2d[i][j] = 0\n",
        "    return arbitrary_mask_2d, inverse_arbitrary_mask_2d\n",
        "\n",
        "\n",
        "# The function tests on the validation set\n",
        "def test(generator, masked_imgs_valid, missing_parts_valid, photos_valid, masks_valid, batch_size):\n",
        "    masked_imgs_valid = masked_imgs_valid[:batch_size]\n",
        "    missing_parts_valid = missing_parts_valid[:batch_size]\n",
        "    photos_valid = photos_valid[:batch_size]\n",
        "    masks_valid = masks_valid[:batch_size]\n",
        "    gen_pred_valid = generator.predict(masked_imgs_valid)\n",
        "    y_hat_multi_mask = np.multiply(gen_pred_valid, masks_valid)\n",
        "    filled_imgs_valid = np.add(y_hat_multi_mask, masked_imgs_valid)\n",
        "    for i in range(7):\n",
        "        f, ax = plt.subplots(1, 6, figsize=(25, 25))\n",
        "        ax[0].imshow(photos_valid[i])\n",
        "        ax[0].set_title(\"photo_valid\")\n",
        "        ax[1].imshow(masked_imgs_valid[i])\n",
        "        ax[1].set_title(\"masked_imgs\")\n",
        "        ax[2].imshow(gen_pred_valid[i])\n",
        "        ax[2].set_title(\"gen_pred valid\")\n",
        "        ax[3].imshow(missing_parts_valid[i])\n",
        "        ax[3].set_title(\"missing_part\")\n",
        "        ax[4].imshow(y_hat_multi_mask[i])\n",
        "        ax[4].set_title(\"y_hat_multi_mask\")\n",
        "        ax[5].imshow(filled_imgs_valid[i])\n",
        "        ax[5].set_title(\"filled_imgs_valid2\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# The function tests on the validation set\n",
        "def test_on_batch(combined_model, masked_imgs_valid, photos_valid, valid, epoch):\n",
        "    global valid_total_loss, train_total_loss\n",
        "    masked_imgs_valid_tmp = masked_imgs_valid\n",
        "    photos_valid_tmp = photos_valid\n",
        "    batches_amount = int(len(masked_imgs_valid) / BATCH_SIZE) - 1\n",
        "    sum_total_loss_valid = 0\n",
        "    for i in range(batches_amount):\n",
        "        batch_size_start = BATCH_SIZE * i\n",
        "        batch_size_end = batch_size_start + BATCH_SIZE\n",
        "        masked_imgs_valid_batch = masked_imgs_valid_tmp[batch_size_start:batch_size_end]\n",
        "        photos_valid_batch = photos_valid_tmp[batch_size_start:batch_size_end]\n",
        "        g_valid_loss = combined_model.test_on_batch(masked_imgs_valid_batch, [photos_valid_batch, valid])\n",
        "        sum_total_loss_valid += g_valid_loss[0]\n",
        "\n",
        "        print(\"%d , valid_loss_1: %f , valid_loss_2: %f\" % (epoch, g_valid_loss[0], g_valid_loss[1]))\n",
        "\n",
        "    avg_total_loss = sum_total_loss_valid / batches_amount\n",
        "    valid_total_loss.append(avg_total_loss)\n",
        "    # Plot the validation progress\n",
        "    if epoch % 5 == 0:\n",
        "        show_train_and_valid_graph()\n",
        "\n",
        "\n",
        "# The function presents graphic results\n",
        "def show_train_and_valid_graph():\n",
        "    plt.title('Model Total Loss')\n",
        "    plt.ylabel('Total loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.plot(valid_total_loss, label=\"valid\")\n",
        "    plt.plot(train_total_loss, label=\"train\")\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "\n",
        "# The function trains the model\n",
        "def train(combined_model, generator, discriminator, masked_imgs_train, missing_parts_train, masked_imgs_valid,\n",
        "          missing_parts_valid, photos_train, photos_valid, masks_train, masks_valid, epochs, batch_size):\n",
        "    global train_total_loss\n",
        "    batches_amount = int(len(masked_imgs_train) / BATCH_SIZE) - 1\n",
        "    real = np.ones((batch_size, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE, 1))  # (64, 14, 14, 1)\n",
        "    fake = np.zeros((batch_size, DISC_OUTPUT_SIZE, DISC_OUTPUT_SIZE, 1))  # (64, 14, 14, 1)\n",
        "    for epoch in range(epochs):\n",
        "        sum_total_loss_train = 0\n",
        "        # train discriminator\n",
        "        masked_imgs_train_shuff, missing_parts_train_shuff, photos_train_shuff = shuffle_data(masked_imgs_train,\n",
        "                                                                                              missing_parts_train,\n",
        "                                                                                              photos_train)\n",
        "        masked_imgs_train_tmp = masked_imgs_train_shuff\n",
        "        photos_train_tmp = photos_train_shuff\n",
        "        for i in range(batches_amount):\n",
        "            batch_size_start = BATCH_SIZE * i\n",
        "            batch_size_end = batch_size_start + BATCH_SIZE\n",
        "            masked_imgs = masked_imgs_train_tmp[batch_size_start:batch_size_end]\n",
        "            photos_train_batch = photos_train_tmp[batch_size_start:batch_size_end]\n",
        "\n",
        "            # the prediction result\n",
        "            gen_pred = generator.predict(masked_imgs)\n",
        "\n",
        "            # Train the discriminator\n",
        "            d_loss_real = discriminator.train_on_batch(photos_train_batch, real)\n",
        "            d_loss_fake = discriminator.train_on_batch(gen_pred, fake)\n",
        "            d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
        "\n",
        "            # Train the Generator\n",
        "            g_loss = combined_model.train_on_batch(masked_imgs, [photos_train_batch, real])\n",
        "\n",
        "            sum_total_loss_train += g_loss[0]\n",
        "\n",
        "            print(\" Epoch:%d -- Discrimnator loss: %f -- Accuracy: %.2f%% -- Generator loss: %f -- Mse: %f\" % (\n",
        "                epoch, d_loss[0], 100 * d_loss[1], g_loss[0], g_loss[1]))\n",
        "\n",
        "        avg_total_loss = sum_total_loss_train / batches_amount\n",
        "        train_total_loss.append(avg_total_loss)\n",
        "\n",
        "        test(generator, masked_imgs_valid, missing_parts_valid, photos_valid, masks_valid, batch_size)\n",
        "        test_on_batch(combined_model, masked_imgs_valid, photos_valid, real, epoch)\n",
        "        save_best_model(generator, epoch)\n",
        "\n",
        "\n",
        "# The function loads the best model found\n",
        "def load_best_model(masked_imgs_valid, photos_valid, masks_valid):\n",
        "    model = keras.models.load_model(\"best_model.h5\")\n",
        "    masked_imgs_valid = masked_imgs_valid[:BATCH_SIZE]\n",
        "    photos_valid = photos_valid[:BATCH_SIZE]\n",
        "    masks_valid = masks_valid[:BATCH_SIZE]\n",
        "    gen_pred_valid = model.predict(masked_imgs_valid)\n",
        "    y_hat_multi_mask = np.multiply(gen_pred_valid, masks_valid)\n",
        "    filled_imgs_valid = np.add(y_hat_multi_mask, masked_imgs_valid)\n",
        "    for i in range(7):\n",
        "        f, ax = plt.subplots(1, 5, figsize=(25, 25))\n",
        "        ax[0].imshow(photos_valid[i])\n",
        "        ax[0].set_title(\"photo_valid\")\n",
        "        ax[1].imshow(masked_imgs_valid[i])\n",
        "        ax[1].set_title(\"masked_imgs\")\n",
        "        ax[2].imshow(gen_pred_valid[i])\n",
        "        ax[2].set_title(\"gen_pred_valid\")\n",
        "        ax[3].imshow(y_hat_multi_mask[i])\n",
        "        ax[3].set_title(\"y_hat_multi_mask\")\n",
        "        ax[4].imshow(filled_imgs_valid[i])\n",
        "        ax[4].set_title(\"filled_imgs_valid2\")\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "# The function saves the best model found\n",
        "def save_best_model(model, epoch):\n",
        "    global MIN_VALID_TOTAL_LOSS\n",
        "    if valid_total_loss[epoch] < MIN_VALID_TOTAL_LOSS:\n",
        "        MIN_VALID_TOTAL_LOSS = valid_total_loss[epoch]\n",
        "        print(\"----------------------------------------- saved model ------------------------------------------\")\n",
        "        model.save(\"best_model.h5\")\n",
        "\n",
        "\n",
        "def test_data():\n",
        "    dir_name = DATA_PATH\n",
        "    dir_list = os.listdir(dir_name)\n",
        "    dir_list = sorted(dir_list)\n",
        "\n",
        "    resize_and_rescale = tf.keras.Sequential([\n",
        "        layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE)\n",
        "        , layers.experimental.preprocessing.Rescaling(1. / 255)\n",
        "    ])\n",
        "\n",
        "    masked_imgs_valid = []\n",
        "    photos_valid = []\n",
        "    masks_valid = []\n",
        "\n",
        "    for idx, item in enumerate(dir_list):\n",
        "        if item == \".DS_Store\":\n",
        "            continue\n",
        "        if idx % 2 == 0:\n",
        "            if dir_name == \"./test/photos_region\":\n",
        "                photo_path = dir_name + \"/\" + dir_list[idx - 1]\n",
        "                mask_path = dir_name + \"/\" + dir_list[idx]\n",
        "            elif dir_name == \"./test/photos_blocks\" or dir_name == \"./test/monet_central_block\" or dir_name == \"./test/monet_blocks\":\n",
        "                photo_path = dir_name + \"/\" + dir_list[idx]\n",
        "                mask_path = dir_name + \"/\" + dir_list[idx - 1]\n",
        "            else:\n",
        "                photo_path = dir_name + \"/\" + dir_list[idx - 1]\n",
        "                mask_path = dir_name + \"/\" + dir_list[idx]\n",
        "            photo = plt.imread(photo_path)\n",
        "            edited_photo = resize_and_rescale(photo)\n",
        "            mask = plt.imread(mask_path)\n",
        "            edited_mask = resize_and_rescale(mask)\n",
        "            edited_photo = edited_photo - edited_mask\n",
        "            masked_imgs_valid.append(edited_photo)\n",
        "            photos_valid.append(edited_photo)\n",
        "            masks_valid.append(edited_mask)\n",
        "\n",
        "    masked_imgs_valid = np.asarray(masked_imgs_valid)\n",
        "    photos_valid = np.asarray(photos_valid)\n",
        "    masks_valid = np.asarray(masks_valid)\n",
        "\n",
        "    model = keras.models.load_model(TRAINED_MODEL_NAME)\n",
        "    gen_pred_valid = model.predict(masked_imgs_valid)\n",
        "    gen_pred_valid = np.asarray(gen_pred_valid)\n",
        "    y_hat_multi_mask = np.multiply(gen_pred_valid, masks_valid)\n",
        "    filled_imgs_valid = np.add(y_hat_multi_mask, masked_imgs_valid)\n",
        "    for i in range(len(masked_imgs_valid)):\n",
        "        f, ax = plt.subplots(1, 2, figsize=(10, 10))\n",
        "        ax[0].imshow(masked_imgs_valid[i])\n",
        "        ax[1].imshow(filled_imgs_valid[i])\n",
        "        plt.show()"
      ],
      "metadata": {
        "id": "YygMRM2YcGE_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Run the desired main**\n"
      ],
      "metadata": {
        "id": "-aSRltz_cXmE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Run the desired main - FOR EXAMPLE:\n",
        "# main_test() for testing trained model\n",
        "# or\n",
        "# main_train() for training\n",
        "def main_train():\n",
        "    get_arbitrary_mask()\n",
        "    masked_imgs_train, missing_parts_train, photos_train, masks_train = load_data(TRAIN_PATH)\n",
        "    masked_imgs_valid, missing_parts_valid, photos_valid, masks_valid = load_data(VALID_PATH)\n",
        "    generator, discriminator, combined_model = init_contextEncoder()\n",
        "    train(combined_model, generator, discriminator, masked_imgs_train, missing_parts_train, masked_imgs_valid,\n",
        "          missing_parts_valid, photos_train, photos_valid, masks_train, masks_valid, epochs=EPOCHS,\n",
        "          batch_size=BATCH_SIZE)\n",
        "\n",
        "\n",
        "def main_test():\n",
        "    test_data()\n"
      ],
      "metadata": {
        "id": "85kXHM6Fb12P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_test()"
      ],
      "metadata": {
        "id": "-s1rrTr0mSQ2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_train()"
      ],
      "metadata": {
        "id": "w9WoY2TosWeo"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "machine_shape": "hm",
      "name": "deep-learning-final.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}